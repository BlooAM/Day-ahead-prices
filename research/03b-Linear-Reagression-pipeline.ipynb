{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Podział dostępności, eksportu itp na zmienne kategoryczne?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/full_data_filtered.csv')\n",
    "data = data.set_index('timestamp')\n",
    "# data = data.drop(columns=['weekday', 'month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize():\n",
    "    import sweetviz as sv\n",
    "    sweet_report = sv.analyze(data)\n",
    "    sweet_report.show_html('data.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Drop columns that have a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\n",
    "    'Biomass 200 available',\n",
    "    'Gas 200 available',\n",
    "    'HPS 100 available',\n",
    "    'HPS 200 available',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform highly skewed data into categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for highly_skew_series, bins in [('Hard coal 100 available', 2),\n",
    "                                 ('Lignite 500 available', 4),\n",
    "                                 ('Lignite 1000 available', 4),\n",
    "                                 ('CEPS_IMP_lag_24', 2),\n",
    "                                 ('CEPS_IMP_lag_168', 2),\n",
    "                                 ('SEPS_IMP_lag_24', 2),\n",
    "                                 ('SEPS_IMP_lag_168', 2),\n",
    "                                 ('50HzT_EXP_lag_24', 2),\n",
    "                                 ('50HzT_EXP_lag_168', 2),\n",
    "                                 ('SVK_EXP_lag_24', 2),\n",
    "                                 ('SVK_EXP_lag_168', 2),\n",
    "                                 ('SVK_IMP_lag_24', 3),\n",
    "                                 ('SVK_IMP_lag_168', 3),\n",
    "                                 ('LIT_EXP_lag_24', 2),\n",
    "                                 ('LIT_EXP_lag_168', 2),\n",
    "                                 ('LIT_IMP_lag_24', 3),\n",
    "                                 ('LIT_IMP_lag_168', 3),\n",
    "                                 ('Biomass 200 generation_lag_24', 2),\n",
    "                                 ('Biomass 200 generation_lag_168', 2),\n",
    "                                 ('HPS 100 generation_lag_24', 2),\n",
    "                                 ('HPS 100 generation_lag_168', 2),\n",
    "                                 ('HPS 200 generation_lag_24', 2),\n",
    "                                 ('HPS 200 generation_lag_168', 2),\n",
    "                                 ]:\n",
    "    data[highly_skew_series] = pd.cut(data[highly_skew_series], bins=bins, labels=list(range(bins)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_benchmark():\n",
    "    external_predictions = pd.read_csv('data/external_predictions.csv')\n",
    "    external_predictions.rename(columns={'Unnamed: 0': 'timestamp'}, inplace=True)\n",
    "    external_predictions.set_index('timestamp', inplace=True)\n",
    "    real_vs_external_predictions = external_predictions.merge(data['price'], left_index=True, right_index=True)\n",
    "    rmse_benchmark = mean_squared_error(real_vs_external_predictions['price'], real_vs_external_predictions['forecast_PLN'], squared=False)\n",
    "    return rmse_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=['price'])\n",
    "y = data[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=180*24,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_columns = ['weekday', 'month']\n",
    "num_columns = list(set(X.columns).difference(set(cat_columns)))\n",
    "num_columns.sort()\n",
    "# num_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Get pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_coefficient_importance(pipeline):\n",
    "    coefficients = pipeline.named_steps['regression'].coef_\n",
    "    columns = X.columns\n",
    "    coefficients_importance = list(zip(columns, coefficients))\n",
    "    coefficients_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    return coefficients_importance\n",
    "\n",
    "def get_model_result(model):\n",
    "    transformer_numerical = Pipeline(steps=[('num_trans', StandardScaler())])\n",
    "    transformer_categorical = Pipeline(steps=[('cat_trans', OneHotEncoder())])\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('numerical', transformer_numerical, num_columns),\n",
    "        ('categorical', transformer_categorical, cat_columns),\n",
    "    ])\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regression', model),\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    rmse_result = mean_squared_error(y_test['price'], pipe.predict(X_test), squared=False)\n",
    "    return rmse_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def check_all_models():\n",
    "    print(f'BENCHMARK: {round(get_benchmark(), 2)}\\n')\n",
    "\n",
    "    results = []\n",
    "\n",
    "    linear_regression_models = [LinearRegression()]\n",
    "    ridge_models = [Ridge(alpha=a, max_iter=10000)\n",
    "                    for a in [0.001, 0.01, 0.1, 1, 2, 5, 10, 25, 50, 100, 250, 1000]]\n",
    "    lasso_models = [Lasso(alpha=a, max_iter=10000)\n",
    "                    for a in [0.001, 0.01, 0.1, 1, 2, 5, 10, 25, 50, 100, 250, 1000]]\n",
    "    elastic_net_models = [ElasticNet(alpha=a, l1_ratio=l, max_iter=10000)\n",
    "                          for a in [0.001, 0.01, 0.1, 1, 2, 5, 10, 25, 50, 100, 250, 1000]\n",
    "                          for l in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]]\n",
    "\n",
    "    models = linear_regression_models + ridge_models + lasso_models + elastic_net_models\n",
    "\n",
    "    for model_ in models:\n",
    "        results.append((model_, round(get_model_result(model_), 2)))\n",
    "\n",
    "    results.sort(key=lambda x: x[1])\n",
    "    print(results)\n",
    "\n",
    "# Best without transformations: 37.68\n",
    "# Best with categorical transformation: 37.15\n",
    "\n",
    "# check_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Lasso(alpha=1, max_iter=10000), 37.15),\n",
       " (Lasso(alpha=0.1, max_iter=10000), 37.34),\n",
       " (ElasticNet(alpha=0.1, l1_ratio=0.9, max_iter=10000), 37.36),\n",
       " (ElasticNet(alpha=0.1, l1_ratio=0.8, max_iter=10000), 37.48),\n",
       " (ElasticNet(alpha=0.1, l1_ratio=0.7, max_iter=10000), 37.59),\n",
       " (Lasso(alpha=2, max_iter=10000), 37.63),\n",
       " (ElasticNet(alpha=0.1, l1_ratio=0.6, max_iter=10000), 37.7),\n",
       " (ElasticNet(alpha=0.1, max_iter=10000), 37.83),\n",
       " (ElasticNet(alpha=1, l1_ratio=0.9, max_iter=10000), 37.94),\n",
       " (Ridge(alpha=250, max_iter=10000), 38.47),\n",
       " (ElasticNet(alpha=0.01, l1_ratio=0.01, max_iter=10000), 38.55),\n",
       " (ElasticNet(alpha=0.01, l1_ratio=0.1, max_iter=10000), 38.59),\n",
       " (ElasticNet(alpha=0.01, l1_ratio=0.2, max_iter=10000), 38.65),\n",
       " (Ridge(alpha=100, max_iter=10000), 39.04),\n",
       " (Ridge(alpha=10, max_iter=10000), 40.3),\n",
       " (Ridge(alpha=1, max_iter=10000), 40.64)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results = []\n",
    "best_models = [Lasso(alpha=2, max_iter=10000),\n",
    "               Lasso(alpha=1, max_iter=10000),\n",
    "               Lasso(alpha=0.1, max_iter=10000),\n",
    "               ElasticNet(alpha=0.1, l1_ratio=0.9, max_iter=10000),\n",
    "               ElasticNet(alpha=0.1, l1_ratio=0.8, max_iter=10000),\n",
    "               ElasticNet(alpha=0.1, l1_ratio=0.7, max_iter=10000),\n",
    "               ElasticNet(alpha=1, l1_ratio=0.9, max_iter=10000),\n",
    "               ElasticNet(alpha=0.1, l1_ratio=0.6, max_iter=10000),\n",
    "               Ridge(alpha=250, max_iter=10000),\n",
    "               ElasticNet(alpha=0.01, l1_ratio=0.01, max_iter=10000),\n",
    "               ElasticNet(alpha=0.01, l1_ratio=0.1, max_iter=10000),\n",
    "               ElasticNet(alpha=0.01, l1_ratio=0.2, max_iter=10000),\n",
    "               ElasticNet(alpha=0.1, max_iter=10000),\n",
    "               Ridge(alpha=100, max_iter=10000),\n",
    "               Ridge(alpha=10, max_iter=10000),\n",
    "               Ridge(alpha=1, max_iter=10000),\n",
    "               ]\n",
    "\n",
    "for model_ in best_models:\n",
    "    best_results.append((model_, round(get_model_result(model_), 2)))\n",
    "\n",
    "best_results.sort(key=lambda x: x[1])\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('numerical',\n",
       "                                                  Pipeline(steps=[('num_trans',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['50HzT_EXP_lag_168',\n",
       "                                                   '50HzT_EXP_lag_24',\n",
       "                                                   '50HzT_IMP_lag_168',\n",
       "                                                   '50HzT_IMP_lag_24',\n",
       "                                                   'Biomass 200 '\n",
       "                                                   'generation_lag_168',\n",
       "                                                   'Biomass 200 '\n",
       "                                                   'generation_lag_24',\n",
       "                                                   'CEPS_EXP_lag_168',\n",
       "                                                   'CEPS_EXP_lag_24',\n",
       "                                                   'CEPS_IMP_lag_168',\n",
       "                                                   'CEPS_IMP_lag_24',\n",
       "                                                   'Gas 20...\n",
       "                                                   'Hard coal 1000 '\n",
       "                                                   'generation_lag_168',\n",
       "                                                   'Hard coal 1000 '\n",
       "                                                   'generation_lag_24',\n",
       "                                                   'Hard coal 200 available',\n",
       "                                                   'Hard coal 200 '\n",
       "                                                   'generation_lag_168',\n",
       "                                                   'Hard coal 200 '\n",
       "                                                   'generation_lag_24',\n",
       "                                                   'Hard coal 300 available',\n",
       "                                                   'Hard coal 300 '\n",
       "                                                   'generation_lag_168', ...]),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('cat_trans',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['weekday', 'month'])])),\n",
       "                ('regression', Lasso(alpha=1, max_iter=10000))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = Lasso(alpha=1, max_iter=10000)\n",
    "transformer_numerical = Pipeline(steps=[('num_trans', StandardScaler())])\n",
    "transformer_categorical = Pipeline(steps=[('cat_trans', OneHotEncoder())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numerical', transformer_numerical, num_columns),\n",
    "    ('categorical', transformer_categorical, cat_columns),\n",
    "])\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regression', best_model),\n",
    "])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LASSO.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    ">>> dump(best_model, 'LASSO.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
